<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html>
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>/home/bhogan/devel/clusterconf/README.md • clusterconf</title>

<!-- jquery -->
<script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script>

<!-- Font Awesome icons -->
<link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="pkgdown.css" rel="stylesheet">
<script src="jquery.sticky-kit.min.js"></script>
<script src="pkgdown.js"></script>
  
  
<meta property="og:title" content="/home/bhogan/devel/clusterconf/README.md" />
<!-- mathjax -->
<script src='https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->


  </head>

  <body>
    <div class="container template-title-body">
      <header>
      <div class="navbar navbar-inverse navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">clusterconf</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="reference/index.html">Reference</a>
</li>
      </ul>
      
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://anthill.mitre.org/projects/CGRP/issues">
    <span class="fa fa-question-circle fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="https://mustache.mitre.org/projects/CGRP/repos/clusterconf/browse">
    <span class="fa fa-bitbucket fa-lg"></span>
     
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      
      </header>

      <div class="row">
  <div class="contents col-md-12">
    <div class="page-header">
      <h1>/home/bhogan/devel/clusterconf/README.md</h1>
    </div>

<div id="cluster-configurations" class="section level1">
<h1 class="hasAnchor">
<a href="#cluster-configurations" class="anchor"></a>Cluster Configurations</h1>
<div id="purpose" class="section level2">
<h2 class="hasAnchor">
<a href="#purpose" class="anchor"></a>Purpose</h2>
<p>The <code>clusterconf</code> package extends the <a href="https://github.com/rstudio/config"><code>config</code> package</a> to provide a proposed standard for obtaining hadoop cluster configurations from R. This allows configuration details to be handled separately from functionality and alleviates the burden on end users to provide details (assuming one person per cluster bites the bullet for the greater good) when loading a feature package.</p>
</div>
<div id="approach" class="section level2">
<h2 class="hasAnchor">
<a href="#approach" class="anchor"></a>Approach</h2>
<p>The gist of how this is done is by combining YAML configuration details (read by <code>config</code>) with R’s built-in dependency management (i.e., <code>install.packages</code>). So long as child packages (e.g., <code>clusterconf.mycluster</code>) follow certain rules, then feature packages can build declare a dependency on <code>clusterconf</code> and then work with any cluster. The functional interface to ask for configuration values is exposed in the <code>clusterconf</code> packages and the actual configurations and java dependencies are provided via the child, cluster-specific, package.</p>
</div>
<div id="the-child-package" class="section level2">
<h2 class="hasAnchor">
<a href="#the-child-package" class="anchor"></a>The Child Package</h2>
<p>It is unlikely than many (any) implementing packages will be publicly available since they contain information on particular hadoop clusters. Therefore we sketch out here what components are necessary.</p>
<div id="r-code-package-naming-convention" class="section level3">
<h3 class="hasAnchor">
<a href="#r-code-package-naming-convention" class="anchor"></a>R Code &amp; Package Naming Convention</h3>
<p>Only one R function is required. The child package must implement <code>get_cluster_name</code>, which returns a string and that the return value of that function, once spaces are removed and all letters converted to lower-case, match the portion of the package name after the period. For example if <code>get_cluster_name</code> returns <code>"My Cluster"</code> then the R package name needs to be <code>clusterconf.mycluster</code>. The reason for the strict package naming convention is so that <code>clusterconf::list_available_clusters</code> can search both installed packages and packages in any configured repositories (i.e., return of <code>getOption("repos")</code>) for child packages.</p>
<p>The configuration package essentially just has a configuration YAML similar to the one above. When developing this file should be placed in <code>./inst/configs</code> and any java dependencies should go in <code>./inst/java</code>.</p>
</div>
<div id="yaml-configuration" class="section level3">
<h3 class="hasAnchor">
<a href="#yaml-configuration" class="anchor"></a>YAML Configuration</h3>
<p>A YAML configuration file is the main component of the cluster-specific package. It should be placed in <code>&lt;package root&gt;/inst/configs</code> and may be named anything so long as it is a <code>*.yaml</code> file. Though it is unlikely that any one feature package will require all of the information in a configuration file it is good practice to include as much as possible so that a variety of feature packages all work. The configurations are accessed lazily, so errors will only result when a feature package attempts to use a missing configuration.</p>
<p>Below is a sample configuration file with notes (instead of values) about what is expected in each field.</p>
<div class="sourceCode"><pre class="sourceCode R"><code class="sourceCode r">default<span class="op">:</span>
<span class="st">  </span>cluster<span class="op">:</span><span class="st">  </span>
<span class="st">    </span>home<span class="op">:</span><span class="st"> </span>path to hadoop install on edge node e.g., <span class="st">"/usr/hdp/hadoop"</span>
    ha_node<span class="op">:</span><span class="st"> </span>name of high availability node, eg, <span class="st">"mycluster-ha"</span>
    name_node<span class="op">:</span><span class="st"> </span>names of name nodes, e.g., [<span class="st">"mycluster-nn1"</span>, <span class="st">"mycluster-nn2"</span>]
    edge_node<span class="op">:</span><span class="st"> </span>name of edge node, e.g., <span class="st">"mycluster-gw"</span>
    edge_port<span class="op">:</span><span class="st"> </span>port to use to connect to edge node, e.g., <span class="dv">22</span>
  yarn<span class="op">:</span>
<span class="st">    </span>conf_dir<span class="op">:</span><span class="st"> </span>path to yarn configurations on edge node, e.g., <span class="st">"/etc/hadoop/conf"</span>
  spark<span class="op">:</span>
<span class="st">    </span>home<span class="op">:</span><span class="st"> </span>path to spark installation on edge node, e.g., <span class="st">"/usr/hdp/hadoop/spark"</span>
    conf_dir<span class="op">:</span><span class="st"> </span>path to spark configurations on edge node, e.g., <span class="st">"/etc/spark/conf"</span>
    packages<span class="op">:</span><span class="st"> </span>default spark packages to include on the path when starting a session, e.g., [<span class="st">"com.databricks:spark-avro_2.10:2.0.1"</span>, <span class="st">"com.databricks:spark-csv_2.10:1.5.0"</span>]
  spark_sql<span class="op">:</span>
<span class="st">    </span>host<span class="op">:</span><span class="st"> </span>e.g., <span class="st">"mycluster-rm1"</span>
    port<span class="op">:</span><span class="st"> </span>e.g., <span class="st">"10001"</span>
    driver<span class="op">:</span><span class="st"> </span>driver class name, e.g., <span class="st">"org.apache.hive.jdbc.HiveDriver"</span>
    classpath<span class="op">:</span><span class="st"> </span>driver classpath, e.g., [<span class="st">"hive-jdbc.jar"</span>, <span class="st">"hadoop-common-2.6.0.2.2.4.2-2.jar"</span>]
  hive<span class="op">:</span><span class="st"> </span>
<span class="st">    </span>pw_required<span class="op">:</span><span class="st"> </span>default authentication required setting, e.g., false
    host<span class="op">:</span><span class="st"> </span>e.g., <span class="st">"mycluster-rm2"</span>
    port<span class="op">:</span><span class="st"> </span>e.g., <span class="st">"10010"</span>
    driver<span class="op">:</span><span class="st"> </span>driver class name, e.g., <span class="st">"org.apache.hive.jdbc.HiveDriver"</span>
    classpath<span class="op">:</span><span class="st"> </span>driver classpath, e.g., [<span class="st">"hive-jdbc.jar"</span>, <span class="st">"hadoop-common-2.6.0.2.2.4.2-2.jar"</span>]
  drill<span class="op">:</span>
<span class="st">    </span>storage<span class="op">:</span><span class="st"> </span>default storage <span class="kw">name</span> (from drill UI), e.g., <span class="st">"dfs"</span>
    hive_storage<span class="op">:</span><span class="st"> </span>name of hive storage <span class="kw">plugin</span> (<span class="cf">for</span> querying Hive metastore)
    url<span class="op">:</span><span class="st"> </span>connection <span class="kw">URL</span> (equivalent to host <span class="op">+</span><span class="st"> </span>port <span class="cf">for</span> hive but generally more complicated <span class="cf">for</span> drill)
    driver<span class="op">:</span><span class="st"> </span>driver class name, e.g., <span class="st">"org.apache.drill.jdbc.Driver"</span>
    classpath<span class="op">:</span><span class="st"> </span>driver classpath, e.g., <span class="st">"drill-jdbc-all-1.6.0.jar"</span>
  webhdfs<span class="op">:</span>
<span class="st">    </span>port<span class="op">:</span><span class="st"> </span>connection port, e.g., <span class="st">"50070"</span>
    suffix<span class="op">:</span><span class="st"> </span>the part of the webhdfs URL after the port, e.g., <span class="st">"webhdfs/v1"</span>
  tools<span class="op">:</span>
<span class="st">    </span>avro<span class="op">:</span><span class="st"> </span>path to avro<span class="op">-</span>tools on edge node, e.g., <span class="st">"/lib/avro-tools-1.7.7.jar"</span>
    parquet<span class="op">:</span><span class="st"> </span>path to parquet<span class="op">-</span>tools on edge node, e.g., <span class="st">"/lib/parquet-tools-1.8.1.jar"</span>
  resources<span class="op">:</span>
<span class="st">    </span>package<span class="op">:</span><span class="st"> </span>package containing java resources, e.g., <span class="st">"clusterconf.myothercluster"</span>
    directory<span class="op">:</span><span class="st"> </span>a directory containing java resources</code></pre></div>
<p>A few notes:</p>
<ul>
<li><p>Not all configurations are required to make a given connection. This configuration file is also used by other HDFS-integration packages. For example, the entire <code>spark</code> and <code>yarn</code> sections could be omitted if SQL on hadoop is the only use case.</p></li>
<li><p>The <code>resources</code> section needs an entry in <em>either</em> the <code>package</code> or <code>directory</code> field. Not both.</p></li>
<li><p>The <code>package</code> option in the <code>resources</code> section enables less duplication of java dependencies. Thus, for example, if your organization has several hadoop clusters then <code>clusterconf.cluster2</code> can declare a dependency (in the <code>imports</code> section of the DESCRIPTION file) on <code>clusterconf.cluster1</code> and the cluster 1 package can be the only one that is bloated with driver jars and other such dependencies.</p></li>
<li><p>The <code>package</code> option in the <code>resources</code> section may be self referential. Extending the example from above, the line in the YAML file may read: <code>package: clusterconf.cluster1</code> for <em>both</em> the cluster 1 package and the cluster 2 package.</p></li>
<li><p>Make sure that there is a line break to end the file. If the file ends on a line with text it will not break things, but a warning will be printed every time it is parsed.</p></li>
</ul>
</div>
<div id="java-dependencies" class="section level3">
<h3 class="hasAnchor">
<a href="#java-dependencies" class="anchor"></a>Java Dependencies</h3>
<p>Java dependencies should be placed in <code>&lt;package root&gt;/inst/java</code>. It is expected that exact name matches should be found. Using the above YAML configuration as an example, if the package reference was self referential then <code>clusterconf</code> will expect that <code>hive-jdbc.jar</code> will exactly be found in the aforementioned directory.</p>
</div>
</div>
</div>

  </div>

</div>


      <footer>
      <div class="copyright">
  <p>Developed by Matt Pollock, Brendan Hogan.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
   </div>

  </body>
</html>

